@incollection{Gawronski2011,
abstract = {A large proportion of research in social psychology uses self-report measures to assess socially relevant constructs, such as attitudes, stereo-types, self-concepts, and self-esteem. Over the past century, self-report measures have provided important insights that built the foundation for many prominent theories in the field. At the same time, there have been per-sistent concerns that self-report measures are suboptimal research tools for at least two reasons. First, responses on self-report measures are susceptible to self-presentation, which may distort measurement outcomes in socially sensitive domains (Crowne {\&} Marlowe, 1960; Paulhus, 1984). Second, there is consensus that many psychological processes operate outside of conscious awareness, which undermines the suitability of self-report mea-su.res to assess mental contents that are introspectively inaccessible (Nisbett {\&} Wilson, 1977). To overcome these problems, psychologists have devel-oped various indirect measurement procedures that (1) reduce participants' ability to control their responses, and (2) do not require introspection for the assessment of mental contents. This chapter reviews a particularly influential class of indirect mea-78 ' • ," Response Interference Tasks 79 surement procedures, namely, experimental paradigms based on response interference (RI). 1 For this purpose, we first provide a general context for our review of RI tasks by defining a number of relevant concepts and briefly describing the history of RI tasks in social psychology. After explaining the basic logic of RI, we then review different kinds of measures based on RI, including general information about their procedures, implementation, and scoring. We conclude our chapter with a discussion of general issues regarding the interpretation of RI effects and a pragmatically oriented com-parison of the reviewed tasks. {\_}Bask Co{\~{}}cepts and Terminology},
address = {New York, NY},
author = {Gawronski, B and Deutsch, R and Banse, R},
booktitle = {Cognitive methods in social psychology},
chapter = {3},
editor = {Klauer, K and Stahl, C and Voss, A},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gawronski, Deutsch, Banse - 2011 - Response interference tasks as indirect measures of automatic associations.pdf:pdf},
isbn = {1462509134},
keywords = {reliability},
mendeley-tags = {reliability},
number = {1},
pages = {78--123},
publisher = {Guilford},
title = {{Response interference tasks as indirect measures of automatic associations}},
year = {2011}
}
@phdthesis{DeSchryver2018,
author = {{De Schryver}, Maarten},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schryver - 2018 - A psychometric analysis of choice reaction time measures.pdf:pdf},
keywords = {reliability},
mendeley-tags = {reliability},
school = {Ghent University},
title = {{A psychometric analysis of choice reaction time measures}},
year = {2018}
}
@article{Rodebaugh2016,
author = {Rodebaugh, Thomas and Scullin, Rachel and Langer, Julia and Dixon, David and Huppert, Jonathan and Bernstein, Amit and Zvielli, Ariel and Lenze, Eric},
doi = {10.1037/abn0000184},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodebaugh et al. - 2016 - Unreliability as a Threat to Understanding Psychopathology The Cautionary Tale of Attentional Bias.pdf:pdf},
isbn = {0000000000000},
issn = {1527-5418},
journal = {Journal of Abnormal Psychology},
keywords = {reliability},
mendeley-tags = {reliability},
number = {6},
pages = {840--851},
title = {{Unreliability as a Threat to Understanding Psychopathology: The Cautionary Tale of Attentional Bias}},
volume = {125},
year = {2016}
}
@article{LeBel2011,
abstract = {Implicit measures have contributed to important insights in almost every area of psychology. However, various issues and challenges remain concerning their use, one of which is their considerable variation in reliability, with many implicit measures having questionable reliability. The goal of the present investigation was to examine an overlooked consequence of this liability with respect to replication, when such implicit measures are used as dependent variables in experimental studies. Using a Monte Carlo simulation, the authors demonstrate that a higher level of unreliability in such dependent variables is associated with substantially lower levels of replicability. The results imply that this overlooked consequence can have far-reaching repercussions for the development of a cumulative science. The authors recommend the routine assessment and reporting of the reliability of implicit measures and also urge the improvement of implicit measures with low reliability.},
author = {LeBel, Etienne P. and Paunonen, Sampo V.},
doi = {10.1177/0146167211400619},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/LeBel, Paunonen - 2011 - Sexy But Often Unreliable The Impact of Unreliability on the Replicability of Experimental Findings With Implic.pdf:pdf},
isbn = {1552-7433 (Electronic)$\backslash$r0146-1672 (Linking)},
issn = {0146-1672, 1552-7433},
journal = {Personality and Social Psychology Bulletin},
keywords = {2010,if data,implicit measures,measurement error,received may 21,reliability,repeatable experiments,replicability,replication,revision accepted november 13,science is concerned with},
mendeley-tags = {reliability},
number = {4},
pages = {570--583},
pmid = {21441219},
title = {{Sexy But Often Unreliable: The Impact of Unreliability on the Replicability of Experimental Findings With Implicit Measures}},
url = {http://psp.sagepub.com.proxy.bibliotheques.uqam.ca:2048/content/37/4/570{\%}5Cnhttp://psp.sagepub.com.proxy.bibliotheques.uqam.ca:2048/content/37/4/570.full.pdf},
volume = {37},
year = {2011}
}
@article{DeSchryver2016,
abstract = {LeBel and Paunonen (2011) highlight that despite their importance and popularity in both theoretical and applied research, many implicit measures continue to be plagued by a persistent and troublesome issue – low reliability. In their paper, they offer a conceptual analysis of the relationship between reliability, power and replicability, and then provide a series of recommendations for researchers interested in using implicit measures in an experimental setting. At the core of their account is the idea that reliability can be equated with statistical power, such that “lower levels of reliability are associated with decreasing probabilities of detecting a statistically significant effect, given one exists in the population” (p.573). They also take the additional step of equating reliability and replicability. In our commentary, we draw attention to the fact that there is no direct, fixed or one-to-one relation between reliability and power or replicability. In our commentary, we draw attention to the fact that there is no direct, fixed or one-to-one relation between reliability and power or replicability. More specifically, we argue that when adopting an experimental (rather than a correlational) approach, researchers strive to minimize inter-individual variation, which has a direct impact on sample based reliability estimates. We evaluate the strengths and weaknesses of the LeBel and Paunonen's recommendations and refine them where appropriate.},
author = {{De Schryver}, Maarten and Hughes, Sean and Rosseel, Yves and {De Houwer}, Jan},
doi = {10.3389/fpsyg.2015.02039},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/De Schryver et al. - 2016 - Unreliable yet still replicable A comment on lebel and paunonen (2011).pdf:pdf},
isbn = {1664-1078},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Implicit measures,Power,Reliability,Replication,reliability},
mendeley-tags = {reliability},
number = {JAN},
pages = {1--8},
title = {{Unreliable yet still replicable: A comment on lebel and paunonen (2011)}},
volume = {6},
year = {2016}
}
@article{Hedge2017,
author = {Hedge, Craig and Powell, Georgina and Sumner, Petroc},
doi = {10.3758/s13428-017-0935-1},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hedge, Powell, Sumner - 2017 - The reliability paradox Why robust cognitive tasks do not produce reliable individual differences.pdf:pdf},
isbn = {1342801709},
issn = {1554-3528},
journal = {Behavior Research Methods},
keywords = {an annoyance rather,difference scores,his goal is to,individual differences,individual differences have been,reaction,reliability,response control,than a challenge to,the experimenter,time},
mendeley-tags = {reliability},
title = {{The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences}},
url = {http://link.springer.com/10.3758/s13428-017-0935-1},
year = {2017}
}
@misc{Parsons2018,
author = {Parsons, Sam},
keywords = {reliability},
mendeley-tags = {reliability},
title = {{Ignoring measurement reliability is a real-life horror story [Blog post]}},
url = {https://medium.com/@Sam_D_Parsons/ignoring-measurement-reliability-is-a-real-life-horror-story-b98a2517db26},
year = {2018}
}
@article{Kanyongo2007,
abstract = {The relationship between reliability and statistical power is considered, and tables that account for reduced reliability are presented. A series of Monte Carlo experiments were conducted to determine the effect of changes in reliability on parametric and nonparametric statistical methods, including the paired samples dependent t test, pooled-variance independent t test, one-way analysis of variance with three levels, Wilcoxon signed-rank test for paired samples, and Mann-Whitney-Wilcoxon test for independent groups. Power tables were created that illustrate the reduction in statistical power from decreased reliability for given sample sizes. Sample size tables were created to provide the approximate sample sizes required to achieve given levels of statistical power based for several levels of reliability.},
author = {Kanyongo, Gibbs Y and Brooks, Gordon P and Kyei-Blankison, Lydia and Gocmen, Gulsah},
doi = {10.22237/jmasm/1177992480},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanyongo et al. - 2007 - Reliability and statistical power How measurement fallibility affects power and required sample sizes for sever.pdf:pdf},
issn = {15389472},
journal = {Journal of Modern Applied Statistical Methods},
keywords = {Monte Carlo simulations,Pseudorandom generation,correlations,effect size,power calculations,reliability,repeatability,statistics},
mendeley-tags = {reliability},
number = {1},
pages = {81--90},
title = {{Reliability and statistical power: How measurement fallibility affects power and required sample sizes for several parametric and nonparametric statistics}},
volume = {6},
year = {2007}
}
@article{Zimmerman2015,
abstract = {Reliability in classical test theory is a population-dependent concept, defined as a ratio of true-score variance and observed-score variance, where observed-score variance is a sum of true and error components. On the other hand, the power of a statistical significance test is a function of the total variance, irrespective of its decomposition into true and error components. For that reason, the reliability of a dependent variable is a function of the ratio of true-score variance and observed-score variance, whereas statistical power is a function of the sum of the same two variances. Controversies about how reliability is related to statistical power often can be explained by authors' use of the term “reliability” in a general way to mean “consistency,” “precision,” or “dependability,” which does not always correspond to its mathematical definition as a variance ratio. The present note shows how adherence to the mathematical definition can help resolve the issue and presents some derivations and illustrative examples that have further implications for significance testing and practical research.},
author = {Zimmerman, Donald and Zumbo, Bruno},
doi = {10.22237/jmasm/1446350640},
file = {:C$\backslash$:/Users/parsonss/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zimmerman, Zumbo - 2015 - Resolving the Issue of How Reliability is Related to Statistical Power Adhering to Mathematical Definitions.pdf:pdf},
issn = {1538 - 9472},
journal = {Journal of Modern Applied Statistical Methods},
keywords = {reliability},
mendeley-tags = {reliability},
number = {2},
pages = {9--26},
title = {{Resolving the Issue of How Reliability is Related to Statistical Power: Adhering to Mathematical Definitions}},
url = {http://digitalcommons.wayne.edu/jmasm/vol14/iss2/5},
volume = {14},
year = {2015}
}
@article{Parsons2018a,
author = {Parsons, Sam and Kruijt, Anne-wil and Fox, Elaine},
doi = {10.17605/OSF.IO/6KA9Z},
file = {:C$\backslash$:/Users/parsonss/Dropbox/future of cogbias - psychometrics needed paper/paper comments and revisions/Parsons Kruijt Fox - reporting reliability.pdf:pdf},
keywords = {cognitive assessment,psychometrics,reliability,reporting standards,routine reporting of measurement},
mendeley-tags = {reliability},
pages = {1--25},
title = {{Psychological Science needs a standard practice of reporting the reliability of cognitive behavioural measurements}},
url = {https://psyarxiv.com/6ka9z},
year = {2019}
}
@article{zuo_harnessing_2019,
	title = {Harnessing reliability for neuroscience research},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-019-0655-x},
	doi = {10.1038/s41562-019-0655-x},
	language = {en},
	urldate = {2019-07-26},
	journal = {Nature Human Behaviour},
	author = {Zuo, Xi-Nian and Xu, Ting and Milham, Michael Peter},
	month = jun,
	year = {2019},
	note = {00000},
	file = {Zuo et al. - 2019 - Harnessing reliability for neuroscience research.pdf:C\:\\Users\\parsonss\\Zotero\\storage\\V5LQWBPW\\Zuo et al. - 2019 - Harnessing reliability for neuroscience research.pdf:application/pdf}
}